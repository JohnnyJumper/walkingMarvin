{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "\n",
    "env = gym.make('Marvin-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I want to create the neuronNetwork that will take an observation of a enviroment (24 dimensional vector) and returns\n",
    " me an action (4 dimensional vector) I then send this action to env.step and receive a reward. Somehow i need to update\n",
    " the weights of my network using the reward. My reward should be as big as possible. (1 - reward) is my error? \n",
    " Looks like so. \n",
    " I need three layers of neurons. each neuron has a weight property, activation function, function to update the weight\n",
    " Each layer consist of several neurons. I need to use the weight inside the neuron. so layers just run neurons commands\n",
    " and play as a coordinator.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_and_sum(a, b):\n",
    "    result = 0\n",
    "    for i in range(len(a)):\n",
    "        result += a[i] * b[i]\n",
    "    return result\n",
    "\n",
    "\n",
    "class Neuron(object):\n",
    "    def __init__(self, input_counts = 1, activation_function = math.tanh, weights = None,\n",
    "                update_function=None, learning_rate = 0.001, input_layer = False, value = None):\n",
    "        self.input_layer = input_layer\n",
    "        if self.input_layer == False:\n",
    "            self.weights = [random.uniform(-1, 1)] * input_counts if weights == None else weights\n",
    "        self.value = value\n",
    "        self.activation_function = activation_function\n",
    "        self.update_function = self.update_weights if update_function == None else update_function\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def setValue(self, value):\n",
    "        self.value = value\n",
    "        \n",
    "\n",
    "    def __str__(self):\n",
    "        message = \"\\n--------------\\nself.weights: {}\\nself.value: {}\\n--------------\\n\"\n",
    "        if (self.input_layer):\n",
    "            message = \"\\n--------------\\ninput layer: True\\nself.value: {}\\n--------------\\n\"\n",
    "            return message.format(self.value)\n",
    "        return message.format(self.weights, self.value)\n",
    "    \n",
    "        \n",
    "    def activate(self, inputs = None):\n",
    "        if (self.input_layer):\n",
    "            return self.value\n",
    "        self.setValue(self.activation_function(mult_and_sum(inputs, self.weights)))\n",
    "        return self.value\n",
    "    \n",
    "    def update_weights(self, inp, update):\n",
    "        # I should update the weight only if the reward is bigger? \n",
    "        errors = self.learning_rate * (update - self.activate(inp))\n",
    "        self.weights = np.add(self.weights, np.multiply(inp, errors))\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_classifiyer(x):\n",
    "    return x\n",
    "\n",
    "class Layer(object):\n",
    "    def __init__(self, neuron_count, input_counts = 1, neuron_weights = None,\n",
    "                 activation_function = linear_classifiyer):\n",
    "        random.seed()\n",
    "        self.neurons = []\n",
    "        self.input_layer = True if input_counts == 1 else False\n",
    "        \n",
    "        for i in range(neuron_count):\n",
    "            if (neuron_weights != None):\n",
    "                self.neurons.append(Neuron(input_counts, input_layer = self.input_layer, weights = neuron_weights[i]))\n",
    "            else:\n",
    "                self.neurons.append(Neuron(input_counts, input_layer = self.input_layer))\n",
    "    \n",
    "    def setValues(self, inputs):\n",
    "        for index, neuron in enumerate(self.neurons):\n",
    "            neuron.setValue(inputs[index])\n",
    "    \n",
    "    \n",
    "    def __str__(self):\n",
    "        message = \"[input_layer: {},\\nneurons: {}]\"\n",
    "        return message.format(self.input_layer, len(self.neurons))\n",
    "\n",
    "    def update(self, inputs, reward):\n",
    "        if (self.input_layer):\n",
    "            return \n",
    "        for neuron in self.neurons:\n",
    "            neuron.update_weights(inputs, reward)\n",
    "    \n",
    "    def output(self, inputs = None):\n",
    "        layer_output = []\n",
    "        for neuron in self.neurons:\n",
    "            layer_output.append(neuron.activate(inputs))\n",
    "        return layer_output\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to give list of lists and create all layers with all neurons.\n",
    "# I should be able to use the weights inside the list of lists\n",
    "# Need an example of weights\n",
    "# 24 input -> 16 -> 8 -> 4 (output)\n",
    "\n",
    "# First layer -> no weights\n",
    "# Second Layer -> 16 neurons each has 24 inputs and 24 weights. \n",
    "# third layer -> 8 neurons each has 16 inputs and 16 weights.\n",
    "# layer #4 -> 4 neurons each has 4 inputs and 4 weights.\n",
    "\n",
    "#Example\n",
    "\n",
    "# [\n",
    "#  [ [w1, w2, w3, ..., ], [], [], ... , []  ] # second layer consist from 16 arrays of weights. each has length == 24 \n",
    "#  [ [w1, w2, w3, ..., ], [], [], ... , []  ] # third layer and etc...\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Brain(object):\n",
    "    def __init__(self, input_counts, weights):\n",
    "        self.layers = []\n",
    "        self.input_layer = Layer(neuron_count = input_counts)\n",
    "        self.layers.append(self.input_layer)\n",
    "        for i, layerWeight in enumerate(weights):\n",
    "            layer = layerWeight\n",
    "            self.layers.append( Layer(neuron_count = len(layer), input_counts = len(layer[-1]),\n",
    "                                      neuron_weights = layer, activation_function = math.tanh))\n",
    "        self.output_layer = self.layers[-1]\n",
    "        \n",
    "    def __str__(self):\n",
    "        message = \"\\n\\nlayers: {}\\ninput_counts: {},\\noutput_counts: {},\\nhidden_layers: {}\\n\\n\"\n",
    "        return message.format(len(self.layers),\n",
    "                              len(self.layers[0].neurons),\n",
    "                              len(self.layers[-1].neurons),\n",
    "                              len(self.layers) - 2)\n",
    "    \n",
    "    def generate_action(self, data):\n",
    "        self.input_layer.setValues(data)\n",
    "        inputs  = self.input_layer.output()\n",
    "        for hidden_layer in self.layers[1: -1]:\n",
    "            inputs = hidden_layer.output(inputs)\n",
    "        return self.output_layer.output(inputs)\n",
    "    \n",
    "    def learn(self, observation, action, reward):\n",
    "        data = np.concatenate((observation, action), axis=None)\n",
    "        self.input_layer.setValues(data)\n",
    "        layer_input = self.input_layer.output()\n",
    "        for layer in self.layers[1:]:\n",
    "            layer.update(layer_input, reward)\n",
    "            layer_input = layer.output(layer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeRandomWeights(schema):\n",
    "    weights = []\n",
    "    for layer in schema:\n",
    "        neurons = []\n",
    "        for neuron in layer:\n",
    "            neuront = []\n",
    "            for k in range(neuron[0]):\n",
    "                neuront.append(random.uniform(-1, 1))\n",
    "            neurons.append(neuront)\n",
    "        weights.append(neurons)\n",
    "    return weights\n",
    "\n",
    "def createSchema(layers = 1, neurons = [1]):\n",
    "    schema = []\n",
    "    layer_len = neurons[0]\n",
    "    for n in neurons:\n",
    "        layer = []\n",
    "        \n",
    "        for _ in range(n):\n",
    "            layer.append([layer_len])\n",
    "        layer_len = len(layer)\n",
    "        schema.append(layer)\n",
    "    return schema\n",
    "\n",
    "def convertWeightsToNumpy(weights):\n",
    "    w = []\n",
    "    for layer in weights:\n",
    "        for neuron in layer:\n",
    "            for element in neuron:\n",
    "                w.append(element)\n",
    "    return np.array(w)\n",
    "\n",
    "def convertWeightsToList(schema, w):\n",
    "    weights = []\n",
    "    i = 0\n",
    "    for layer in schema:\n",
    "        neurons = []\n",
    "        for neuron in layer:\n",
    "            neuront = []\n",
    "            for k in range(neuron[0]):\n",
    "                neuront.append(w[i])\n",
    "                i = i + 1\n",
    "            neurons.append(neuront)\n",
    "        weights.append(neurons)\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w):\n",
    "    observation = env.reset()\n",
    "    tester = Brain(input_counts = 24, weights = w)\n",
    "    total = 0\n",
    "    for i in range(500):\n",
    "        action = tester.generate_action(observation)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        observation = new_observation\n",
    "        total += reward\n",
    "        if (done == True or reward == -100):\n",
    "            break\n",
    "    return (total, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0. reward: -127.738594\n",
      "steps: 242.6\n",
      "steps: 273.9\n",
      "steps: 347.5\n",
      "steps: 397.6\n",
      "steps: 399.6\n",
      "steps: 456.8\n",
      "steps: 491.5\n",
      "steps: 450.7\n",
      "steps: 454.1\n",
      "steps: 470.8\n",
      "iter 10. reward: -37.925700\n",
      "steps: 464.7\n",
      "steps: 467.5\n",
      "steps: 464.0\n",
      "steps: 440.4\n",
      "steps: 492.2\n",
      "steps: 483.5\n",
      "steps: 442.3\n",
      "steps: 464.4\n",
      "steps: 484.4\n",
      "steps: 483.1\n",
      "iter 20. reward: -22.136087\n",
      "steps: 491.7\n",
      "steps: 491.9\n",
      "steps: 492.2\n",
      "steps: 478.1\n",
      "steps: 495.2\n",
      "steps: 499.0\n",
      "steps: 479.8\n",
      "steps: 485.5\n",
      "steps: 492.5\n",
      "steps: 492.6\n",
      "iter 30. reward: -17.764140\n",
      "steps: 454.8\n",
      "steps: 484.9\n",
      "steps: 483.9\n",
      "steps: 499.0\n",
      "steps: 426.7\n",
      "steps: 460.8\n",
      "steps: 481.5\n",
      "steps: 496.9\n",
      "steps: 486.7\n",
      "steps: 490.9\n",
      "iter 40. reward: 1.428341\n",
      "steps: 497.8\n",
      "steps: 486.3\n",
      "steps: 478.9\n",
      "steps: 485.3\n",
      "steps: 499.0\n",
      "steps: 490.1\n",
      "steps: 461.5\n",
      "steps: 488.3\n",
      "steps: 492.8\n",
      "steps: 474.1\n",
      "iter 50. reward: 69.046562\n",
      "steps: 381.3\n",
      "steps: 484.1\n",
      "steps: 486.7\n",
      "steps: 438.9\n",
      "steps: 499.0\n",
      "steps: 488.2\n",
      "steps: 499.0\n",
      "steps: 473.9\n",
      "steps: 490.1\n",
      "steps: 490.8\n",
      "iter 60. reward: 65.386946\n",
      "steps: 498.7\n",
      "steps: 461.8\n",
      "steps: 499.0\n",
      "steps: 491.4\n",
      "steps: 476.7\n",
      "steps: 499.0\n",
      "steps: 478.7\n",
      "steps: 495.7\n",
      "steps: 476.6\n",
      "steps: 499.0\n",
      "iter 70. reward: -33.186798\n",
      "steps: 481.0\n",
      "steps: 484.8\n",
      "steps: 472.9\n",
      "steps: 480.9\n",
      "steps: 491.4\n",
      "steps: 468.6\n",
      "steps: 453.4\n",
      "steps: 487.4\n",
      "steps: 490.0\n",
      "steps: 488.7\n",
      "iter 80. reward: 81.960746\n",
      "steps: 461.0\n",
      "steps: 410.4\n",
      "steps: 493.6\n",
      "steps: 482.6\n",
      "steps: 480.9\n",
      "steps: 488.3\n",
      "steps: 499.0\n",
      "steps: 445.9\n",
      "steps: 484.7\n",
      "steps: 462.5\n",
      "iter 90. reward: 58.200383\n",
      "steps: 495.5\n",
      "steps: 444.9\n",
      "steps: 467.7\n",
      "steps: 499.0\n",
      "steps: 488.5\n",
      "steps: 496.0\n",
      "steps: 492.6\n",
      "steps: 492.4\n",
      "steps: 491.4\n",
      "steps: 491.7\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "convertWeightsToList() missing 1 required positional argument: 'w'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-65c19aa6faf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnpop\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvertWeightsToList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: convertWeightsToList() missing 1 required positional argument: 'w'"
     ]
    }
   ],
   "source": [
    "npop = 50 # population size\n",
    "sigma = 0.1 # noise standard deviation\n",
    "alpha = 0.05 # learning rate\n",
    "np.random.seed(422142)\n",
    "\n",
    "schema = createSchema(layers=3, neurons = [24, 6, 4])\n",
    "w = convertWeightsToNumpy(initializeRandomWeights(schema))\n",
    "\n",
    "for i in range(100):\n",
    "    if i % 10 == 0:\n",
    "        r = f(convertWeightsToList(schema, w))[0]\n",
    "        print('iter %d. reward: %f' % (i, r))\n",
    "        if (r > 100):\n",
    "              break\n",
    "    N = -2 * np.random.random_sample((npop, w.shape[0])) + 1\n",
    "    R = np.zeros(npop)\n",
    "    steps = 0\n",
    "    for j in range(npop):\n",
    "        w_try = w + sigma*N[j]\n",
    "        R[j], s = f(convertWeightsToList(schema, w_try))\n",
    "        steps += s\n",
    "    print('steps: %.1f' % (steps / npop))\n",
    "    A = (R - np.mean(R)) / np.std(R)\n",
    "    w = w + alpha / (npop*sigma) * np.dot(N.T, A)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1613 233.95733626686956\n"
     ]
    }
   ],
   "source": [
    "weights = convertWeightsToList(schema, w)\n",
    "marvin = Brain(input_counts = 24, weights = weights)\n",
    "total = 0\n",
    "observation = env.reset()\n",
    "for step in range(15000):\n",
    "    env.render()\n",
    "    \n",
    "    action = marvin.generate_action(observation)\n",
    "    \n",
    "    new_observation, reward, done, info = env.step(action)\n",
    "    total += reward\n",
    "    observation = new_observation\n",
    "#     if (step % 10 == 0):\n",
    "#         print (step, reward)\n",
    "    if (done == True): # or total > 100):\n",
    "        break \n",
    "env.close()\n",
    "print(step, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
