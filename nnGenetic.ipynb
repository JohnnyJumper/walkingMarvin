{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "\n",
    "env = gym.make('Marvin-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I want to create the neuronNetwork that will take an observation of a enviroment (24 dimensional vector) and returns\n",
    " me an action (4 dimensional vector) I then send this action to env.step and receive a reward. Somehow i need to update\n",
    " the weights of my network using the reward. My reward should be as big as possible. (1 - reward) is my error? \n",
    " Looks like so. \n",
    " I need three layers of neurons. each neuron has a weight property, activation function, function to update the weight\n",
    " Each layer consist of several neurons. I need to use the weight inside the neuron. so layers just run neurons commands\n",
    " and play as a coordinator.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_and_sum(a, b):\n",
    "    result = 0\n",
    "    for i in range(len(a)):\n",
    "        result += a[i] * b[i]\n",
    "    return result\n",
    "\n",
    "\n",
    "class Neuron(object):\n",
    "    def __init__(self, input_counts = 1, activation_function = math.tanh, weights = None,\n",
    "                update_function=None, learning_rate = 0.001, input_layer = False, value = None):\n",
    "        self.input_layer = input_layer\n",
    "        if self.input_layer == False:\n",
    "            self.weights = [random.uniform(-1, 1)] * input_counts if weights == None else weights\n",
    "        self.value = value\n",
    "        self.activation_function = activation_function\n",
    "        self.update_function = self.update_weights if update_function == None else update_function\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def setValue(self, value):\n",
    "        self.value = value\n",
    "        \n",
    "\n",
    "    def __str__(self):\n",
    "        message = \"\\n--------------\\nself.weights: {}\\nself.value: {}\\n--------------\\n\"\n",
    "        if (self.input_layer):\n",
    "            message = \"\\n--------------\\ninput layer: True\\nself.value: {}\\n--------------\\n\"\n",
    "            return message.format(self.value)\n",
    "        return message.format(self.weights, self.value)\n",
    "    \n",
    "        \n",
    "    def activate(self, inputs = None):\n",
    "        if (self.input_layer):\n",
    "            return self.value\n",
    "        self.setValue(self.activation_function(mult_and_sum(inputs, self.weights)))\n",
    "        return self.value\n",
    "    \n",
    "    def update_weights(self, inp, update):\n",
    "        # I should update the weight only if the reward is bigger? \n",
    "        errors = self.learning_rate * (update - self.activate(inp))\n",
    "        self.weights = np.add(self.weights, np.multiply(inp, errors))\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_classifiyer(x):\n",
    "    return x\n",
    "\n",
    "class Layer(object):\n",
    "    def __init__(self, neuron_count, input_counts = 1, neuron_weights = None,\n",
    "                 activation_function = linear_classifiyer):\n",
    "        random.seed()\n",
    "        self.neurons = []\n",
    "        self.input_layer = True if input_counts == 1 else False\n",
    "        \n",
    "        for i in range(neuron_count):\n",
    "            if (neuron_weights != None):\n",
    "                self.neurons.append(Neuron(input_counts, input_layer = self.input_layer, weights = neuron_weights[i]))\n",
    "            else:\n",
    "                self.neurons.append(Neuron(input_counts, input_layer = self.input_layer))\n",
    "    \n",
    "    def setValues(self, inputs):\n",
    "        for index, neuron in enumerate(self.neurons):\n",
    "            neuron.setValue(inputs[index])\n",
    "    \n",
    "    \n",
    "    def __str__(self):\n",
    "        message = \"[input_layer: {},\\nneurons: {}]\"\n",
    "        return message.format(self.input_layer, len(self.neurons))\n",
    "\n",
    "    def update(self, inputs, reward):\n",
    "        if (self.input_layer):\n",
    "            return \n",
    "        for neuron in self.neurons:\n",
    "            neuron.update_weights(inputs, reward)\n",
    "    \n",
    "    def output(self, inputs = None):\n",
    "        layer_output = []\n",
    "        for neuron in self.neurons:\n",
    "            layer_output.append(neuron.activate(inputs))\n",
    "        return layer_output\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to give list of lists and create all layers with all neurons.\n",
    "# I should be able to use the weights inside the list of lists\n",
    "# Need an example of weights\n",
    "# 24 input -> 16 -> 8 -> 4 (output)\n",
    "\n",
    "# First layer -> no weights\n",
    "# Second Layer -> 16 neurons each has 24 inputs and 24 weights. \n",
    "# third layer -> 8 neurons each has 16 inputs and 16 weights.\n",
    "# layer #4 -> 4 neurons each has 4 inputs and 4 weights.\n",
    "\n",
    "#Example\n",
    "\n",
    "# [\n",
    "#  [ [w1, w2, w3, ..., ], [], [], ... , []  ] # second layer consist from 16 arrays of weights. each has length == 24 \n",
    "#  [ [w1, w2, w3, ..., ], [], [], ... , []  ] # third layer and etc...\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Brain(object):\n",
    "    def __init__(self, input_counts, weights):\n",
    "        self.layers = []\n",
    "        self.input_layer = Layer(neuron_count = input_counts)\n",
    "        self.layers.append(self.input_layer)\n",
    "        for i, layerWeight in enumerate(weights):\n",
    "            layer = layerWeight\n",
    "            self.layers.append( Layer(neuron_count = len(layer), input_counts = len(layer[-1]),\n",
    "                                      neuron_weights = layer, activation_function = math.tanh))\n",
    "        self.output_layer = self.layers[-1]\n",
    "        \n",
    "    def __str__(self):\n",
    "        message = \"\\n\\nlayers: {}\\ninput_counts: {},\\noutput_counts: {},\\nhidden_layers: {}\\n\\n\"\n",
    "        return message.format(len(self.layers),\n",
    "                              len(self.layers[0].neurons),\n",
    "                              len(self.layers[-1].neurons),\n",
    "                              len(self.layers) - 2)\n",
    "    \n",
    "    def generate_action(self, data):\n",
    "        self.input_layer.setValues(data)\n",
    "        inputs  = self.input_layer.output()\n",
    "        for hidden_layer in self.layers[1: -1]:\n",
    "            inputs = hidden_layer.output(inputs)\n",
    "        return self.output_layer.output(inputs)\n",
    "    \n",
    "    def learn(self, observation, action, reward):\n",
    "        data = np.concatenate((observation, action), axis=None)\n",
    "        self.input_layer.setValues(data)\n",
    "        layer_input = self.input_layer.output()\n",
    "        for layer in self.layers[1:]:\n",
    "            layer.update(layer_input, reward)\n",
    "            layer_input = layer.output(layer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeRandomWeights(schema):\n",
    "    weights = []\n",
    "    for layer in schema:\n",
    "        neurons = []\n",
    "        for neuron in layer:\n",
    "            neuront = []\n",
    "            for k in range(neuron[0]):\n",
    "                neuront.append(random.uniform(-1, 1))\n",
    "            neurons.append(neuront)\n",
    "        weights.append(neurons)\n",
    "    return weights\n",
    "\n",
    "def createSchema(layers = 1, neurons = [1]):\n",
    "    schema = []\n",
    "    layer_len = neurons[0]\n",
    "    for n in neurons:\n",
    "        layer = []\n",
    "        \n",
    "        for _ in range(n):\n",
    "            layer.append([layer_len])\n",
    "        layer_len = len(layer)\n",
    "        schema.append(layer)\n",
    "    return schema\n",
    "\n",
    "def convertWeightsToNumpy(weights):\n",
    "    w = []\n",
    "    for layer in weights:\n",
    "        for neuron in layer:\n",
    "            for element in neuron:\n",
    "                w.append(element)\n",
    "    return np.array(w)\n",
    "\n",
    "def convertWeightsToList(schema, w):\n",
    "    weights = []\n",
    "    i = 0\n",
    "    for layer in schema:\n",
    "        neurons = []\n",
    "        for neuron in layer:\n",
    "            neuront = []\n",
    "            for k in range(neuron[0]):\n",
    "                neuront.append(w[i])\n",
    "                i = i + 1\n",
    "            neurons.append(neuront)\n",
    "        weights.append(neurons)\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w):\n",
    "    observation = env.reset()\n",
    "    tester = Brain(input_counts = 24, weights = w)\n",
    "    total = 0\n",
    "    for i in range(500):\n",
    "        action = tester.generate_action(observation)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        observation = new_observation\n",
    "        total += reward\n",
    "        if (done == True or reward == -100 or total > 100):\n",
    "            break\n",
    "    return (total, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./weights.csv')\n",
    "d = np.array(data[\"weight\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Steps: 94.0, Reward: -116.9\n",
      "Episode: 11, Steps: 98.8, Reward: -102.8\n",
      "Episode: 21, Steps: 95.9, Reward: -99.2\n",
      "Episode: 31, Steps: 409.4, Reward: -50.8\n",
      "Episode: 41, Steps: 499.0, Reward: -19.5\n"
     ]
    }
   ],
   "source": [
    "npop = 50 # population size\n",
    "sigma = 0.1 # noise standard deviation\n",
    "alpha = 0.05 # learning rate\n",
    "np.random.seed(422142)\n",
    "\n",
    "schema = createSchema(layers=3, neurons = [24, 6, 4])\n",
    "w = convertWeightsToNumpy(initializeRandomWeights(schema))\n",
    "#w = d\n",
    "i = 0\n",
    "while (True):\n",
    "    N = -2 * np.random.random_sample((npop, w.shape[0])) + 1\n",
    "    R = np.zeros(npop)\n",
    "    steps = 0\n",
    "    reward = 0\n",
    "    for j in range(npop):\n",
    "        w_try = w + sigma*N[j]\n",
    "        R[j], s = f(convertWeightsToList(schema, w_try))\n",
    "        steps += s\n",
    "        reward += R[j]\n",
    "    if (i % 10 == 0):\n",
    "        print('Episode: %d, Steps: %.1f, Reward: %.1f' % (i + 1, steps / npop, reward / npop))\n",
    "    A = (R - np.mean(R)) / np.std(R)\n",
    "    w = w + alpha / (npop*sigma) * np.dot(N.T, A)\n",
    "    if (reward / npop > 100):\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "print(\"Episodes: %d\" % (i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(w, columns=['weight'])\n",
    "data.to_csv('./weights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weights = convertWeightsToList(schema, w)\n",
    "marvin = Brain(input_counts = 24, weights = weights)\n",
    "total = 0\n",
    "observation = env.reset()\n",
    "for step in range(2000):\n",
    "    env.render()\n",
    "    \n",
    "    action = marvin.generate_action(observation)\n",
    "    \n",
    "    new_observation, reward, done, info = env.step(action)\n",
    "    total += reward\n",
    "    if (done == True):\n",
    "        break \n",
    "env.close()\n",
    "print(step, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
