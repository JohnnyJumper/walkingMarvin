{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "\n",
    "env = gym.make('Marvin-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I want to create the neuronNetwork that will take an observation of a enviroment (24 dimensional vector) and returns\n",
    " me an action (4 dimensional vector) I then send this action to env.step and receive a reward. Somehow i need to update\n",
    " the weights of my network using the reward. My reward should be as big as possible. (1 - reward) is my error? \n",
    " Looks like so. \n",
    " I need three layers of neurons. each neuron has a weight property, activation function, function to update the weight\n",
    " Each layer consist of several neurons. I need to use the weight inside the neuron. so layers just run neurons commands\n",
    " and play as a coordinator.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_and_sum(a, b):\n",
    "    result = 0\n",
    "    for i in range(len(a)):\n",
    "        result += a[i] * b[i]\n",
    "    return result\n",
    "\n",
    "\n",
    "class Neuron(object):\n",
    "    def __init__(self, input_counts = 1, activation_function = math.tanh, weights = None,\n",
    "                update_function=None, learning_rate = 0.001, input_layer = False, value = None):\n",
    "        self.input_layer = input_layer\n",
    "        if self.input_layer == False:\n",
    "            self.weights = [random.uniform(-1, 1)] * input_counts if weights == None else weights\n",
    "        self.value = value\n",
    "        self.activation_function = activation_function\n",
    "        self.update_function = self.update_weights if update_function == None else update_function\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def setValue(self, value):\n",
    "        self.value = value\n",
    "        \n",
    "\n",
    "    def __str__(self):\n",
    "        message = \"\\n--------------\\nself.weights: {}\\nself.value: {}\\n--------------\\n\"\n",
    "        if (self.input_layer):\n",
    "            message = \"\\n--------------\\ninput layer: True\\nself.value: {}\\n--------------\\n\"\n",
    "            return message.format(self.value)\n",
    "        return message.format(self.weights, self.value)\n",
    "    \n",
    "        \n",
    "    def activate(self, inputs = None):\n",
    "        if (self.input_layer):\n",
    "            return self.value\n",
    "        self.setValue(self.activation_function(mult_and_sum(inputs, self.weights)))\n",
    "        return self.value\n",
    "    \n",
    "    def update_weights(self, inp, update):\n",
    "        # I should update the weight only if the reward is bigger? \n",
    "        errors = self.learning_rate * (update - self.activate(inp))\n",
    "        self.weights = np.add(self.weights, np.multiply(inp, errors))\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_classifiyer(x):\n",
    "    return x\n",
    "\n",
    "class Layer(object):\n",
    "    def __init__(self, neuron_count, input_counts = 1, neuron_weights = None,\n",
    "                 activation_function = linear_classifiyer):\n",
    "        random.seed()\n",
    "        self.neurons = []\n",
    "        self.input_layer = True if input_counts == 1 else False\n",
    "        \n",
    "        for i in range(neuron_count):\n",
    "            if (neuron_weights != None):\n",
    "                self.neurons.append(Neuron(input_counts, input_layer = self.input_layer, weights = neuron_weights[i]))\n",
    "            else:\n",
    "                self.neurons.append(Neuron(input_counts, input_layer = self.input_layer))\n",
    "    \n",
    "    def setValues(self, inputs):\n",
    "        for index, neuron in enumerate(self.neurons):\n",
    "            neuron.setValue(inputs[index])\n",
    "    \n",
    "    \n",
    "    def __str__(self):\n",
    "        message = \"[input_layer: {},\\nneurons: {}]\"\n",
    "        return message.format(self.input_layer, len(self.neurons))\n",
    "\n",
    "    def update(self, inputs, reward):\n",
    "        if (self.input_layer):\n",
    "            return \n",
    "        for neuron in self.neurons:\n",
    "            neuron.update_weights(inputs, reward)\n",
    "    \n",
    "    def output(self, inputs = None):\n",
    "        layer_output = []\n",
    "        for neuron in self.neurons:\n",
    "            layer_output.append(neuron.activate(inputs))\n",
    "        return layer_output\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to give list of lists and create all layers with all neurons.\n",
    "# I should be able to use the weights inside the list of lists\n",
    "# Need an example of weights\n",
    "# 24 input -> 16 -> 8 -> 4 (output)\n",
    "\n",
    "# First layer -> no weights\n",
    "# Second Layer -> 16 neurons each has 24 inputs and 24 weights. \n",
    "# third layer -> 8 neurons each has 16 inputs and 16 weights.\n",
    "# layer #4 -> 4 neurons each has 4 inputs and 4 weights.\n",
    "\n",
    "#Example\n",
    "\n",
    "# [\n",
    "#  [ [w1, w2, w3, ..., ], [], [], ... , []  ] # second layer consist from 16 arrays of weights. each has length == 24 \n",
    "#  [ [w1, w2, w3, ..., ], [], [], ... , []  ] # third layer and etc...\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Brain(object):\n",
    "    def __init__(self, input_counts, weights):\n",
    "        self.layers = []\n",
    "        self.input_layer = Layer(neuron_count = input_counts)\n",
    "        self.layers.append(self.input_layer)\n",
    "        for i, layerWeight in enumerate(weights):\n",
    "            layer = layerWeight\n",
    "            self.layers.append( Layer(neuron_count = len(layer), input_counts = len(layer[-1]),\n",
    "                                      neuron_weights = layer, activation_function = math.tanh))\n",
    "        self.output_layer = self.layers[-1]\n",
    "        \n",
    "    def __str__(self):\n",
    "        message = \"\\n\\nlayers: {}\\ninput_counts: {},\\noutput_counts: {},\\nhidden_layers: {}\\n\\n\"\n",
    "        return message.format(len(self.layers),\n",
    "                              len(self.layers[0].neurons),\n",
    "                              len(self.layers[-1].neurons),\n",
    "                              len(self.layers) - 2)\n",
    "    \n",
    "    def generate_action(self, data):\n",
    "        self.input_layer.setValues(data)\n",
    "        inputs  = self.input_layer.output()\n",
    "        for hidden_layer in self.layers[1: -1]:\n",
    "            inputs = hidden_layer.output(inputs)\n",
    "        return self.output_layer.output(inputs)\n",
    "    \n",
    "    def learn(self, observation, action, reward):\n",
    "        data = np.concatenate((observation, action), axis=None)\n",
    "        self.input_layer.setValues(data)\n",
    "        layer_input = self.input_layer.output()\n",
    "        for layer in self.layers[1:]:\n",
    "            layer.update(layer_input, reward)\n",
    "            layer_input = layer.output(layer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeRandomWeights(schema):\n",
    "    weights = []\n",
    "    for layer in schema:\n",
    "        neurons = []\n",
    "        for neuron in layer:\n",
    "            neuront = []\n",
    "            for k in range(neuron[0]):\n",
    "                neuront.append(random.uniform(-1, 1))\n",
    "            neurons.append(neuront)\n",
    "        weights.append(neurons)\n",
    "    return weights\n",
    "\n",
    "def createSchema(layers = 1, neurons = [1]):\n",
    "    schema = []\n",
    "    layer_len = neurons[0]\n",
    "    for n in neurons:\n",
    "        layer = []\n",
    "        \n",
    "        for _ in range(n):\n",
    "            layer.append([layer_len])\n",
    "        layer_len = len(layer)\n",
    "        schema.append(layer)\n",
    "    return schema\n",
    "\n",
    "def convertWeightsToNumpy(weights):\n",
    "    w = []\n",
    "    for layer in weights:\n",
    "        for neuron in layer:\n",
    "            for element in neuron:\n",
    "                w.append(element)\n",
    "    return np.array(w)\n",
    "\n",
    "def convertWeightsToList(schema, w):\n",
    "    weights = []\n",
    "    i = 0\n",
    "    for layer in schema:\n",
    "        neurons = []\n",
    "        for neuron in layer:\n",
    "            neuront = []\n",
    "            for k in range(neuron[0]):\n",
    "                neuront.append(w[i])\n",
    "                i = i + 1\n",
    "            neurons.append(neuront)\n",
    "        weights.append(neurons)\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w):\n",
    "    observation = env.reset()\n",
    "    tester = Brain(input_counts = 24, weights = w)\n",
    "    total = 0\n",
    "    for i in range(300):\n",
    "        action = tester.generate_action(observation)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        observation = new_observation\n",
    "        total += reward\n",
    "        if (done == True or reward == -100 or total > 100):\n",
    "            break\n",
    "    env.close()\n",
    "    return (total, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./weights-422142-300-005.csv')\n",
    "d = np.array(data[\"weight\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Steps: 295.8, Reward: 30.9\n",
      "Episode: 11, Steps: 299.0, Reward: 59.5\n",
      "Episode: 21, Steps: 299.0, Reward: 61.0\n",
      "Episode: 31, Steps: 292.7, Reward: 55.1\n",
      "Episode: 41, Steps: 298.3, Reward: 63.0\n",
      "Episode: 51, Steps: 296.1, Reward: 56.0\n",
      "Episode: 61, Steps: 299.0, Reward: 64.2\n",
      "Episode: 71, Steps: 299.0, Reward: 63.8\n",
      "Episode: 81, Steps: 298.8, Reward: 67.6\n",
      "Episode: 91, Steps: 295.1, Reward: 64.5\n",
      "Episode: 101, Steps: 299.0, Reward: 67.1\n",
      "Episode: 111, Steps: 297.4, Reward: 65.4\n",
      "Episode: 121, Steps: 296.6, Reward: 65.9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-247fe8db36c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mw_try\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvertWeightsToList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_try\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-dfd93c3cd9e4>\u001b[0m in \u001b[0;36mf\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mnew_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-d30d45637fdb>\u001b[0m in \u001b[0;36mgenerate_action\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhidden_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f46c40ae9522>\u001b[0m in \u001b[0;36moutput\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mneuron\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mlayer_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "npop = 80 # population size\n",
    "sigma = 0.1 # noise standard deviation\n",
    "alpha = 0.05 # learning rate\n",
    "np.random.seed(422142)\n",
    "\n",
    "schema = createSchema(layers=3, neurons = [24, 6, 4])\n",
    "#w = convertWeightsToNumpy(initializeRandomWeights(schema))\n",
    "w = d\n",
    "i = 0\n",
    "while (True):\n",
    "    N = np.random.random_sample((npop, w.shape[0]))\n",
    "    R = np.zeros(npop)\n",
    "    steps = 0\n",
    "    reward = 0\n",
    "    for j in range(npop):\n",
    "        w_try = w + sigma * N[j]\n",
    "        R[j], s = f(convertWeightsToList(schema, w_try))\n",
    "        steps += s\n",
    "        reward += R[j]\n",
    "    if (i % 10 == 0):\n",
    "        print('Episode: %d, Steps: %.1f, Reward: %.1f' % (i + 1, steps / npop, reward / npop))\n",
    "    A = (R - np.mean(R)) / np.std(R)\n",
    "    w = w + alpha / (npop * sigma) * np.dot(N.T, A)\n",
    "    if (reward / npop > 100):\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "print(\"Episodes: %d\" % (i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(w, columns=['weight'])\n",
    "data.to_csv('./weights-422142-300-005.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convertWeightsToList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-92cf02cf6c2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvertWeightsToList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmarvin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'convertWeightsToList' is not defined"
     ]
    }
   ],
   "source": [
    "weights = convertWeightsToList(schema, w)\n",
    "marvin = Brain(input_counts = 24, weights = weights)\n",
    "total = 0\n",
    "observation = np.random.random_sample(24)\n",
    "observation = env.reset()\n",
    "for step in range(20000):\n",
    "    env.render()\n",
    "    \n",
    "    action = marvin.generate_action(observation)\n",
    "    \n",
    "    observation, reward, done, info = env.step(action)\n",
    "    total += reward\n",
    "    if (done == True):\n",
    "        break \n",
    "env.close()\n",
    "print(step, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
