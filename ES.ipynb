{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(214221)\n",
    "env = gym.make('Marvin-v0')\n",
    "observation = env.reset()\n",
    "\n",
    "# the function we want to optimize\n",
    "def f(w):\n",
    "    # here we would normally:\n",
    "    # ... 1) create a neural network with weights w\n",
    "    # ... 2) run the neural network on the environment for some time\n",
    "    # ... 3) sum up and return the total reward\n",
    "\n",
    "    # but for the purposes of an example, lets try to minimize\n",
    "    # the L2 distance to a specific solution vector. So the highest reward\n",
    "    # we can achieve is 0, when the vector w is exactly equal to solution\n",
    "    total = 0\n",
    "    for i in range(1000):\n",
    "        observation, reward, done, info = env.step(w)\n",
    "        total += reward\n",
    "        if (done == True or reward == -100 or reward == 100):\n",
    "            break\n",
    "    observation = env.reset()\n",
    "    return (total, i)\n",
    "\n",
    "# hyperparameters\n",
    "npop = 50 # population size\n",
    "sigma = 0.1 # noise standard deviation\n",
    "alpha = 0.05 # learning rate\n",
    "\n",
    "# start the optimization\n",
    "w = -2 *  np.random.random_sample((4)) + 1 # our initial guess is random\n",
    "\n",
    "# for i in range(100):\n",
    "#     # print current fitness of the most likely parameter setting\n",
    "#     if i % 10 == 0:\n",
    "#         print('iter %d. w: %s, reward: %f' % (i, str(w), f(w)[0]))\n",
    "\n",
    "#     # initialize memory for a population of w's, and their rewards\n",
    "#     N = -2 *  np.random.random_sample((npop, 4)) + 1 # samples from a normal distribution N(0,1)\n",
    "#     R = np.zeros(npop)\n",
    "#     steps = 0\n",
    "#     for j in range(npop):\n",
    "#         w_try = w + sigma*N[j] # jitter w using gaussian of sigma 0.1\n",
    "#         R[j], s = f(w_try) # evaluate the jittered version\n",
    "#         steps += s\n",
    "#     print('steps: %.1f' % (steps / npop))\n",
    "#     # standardize the rewards to have a gaussian distribution\n",
    "#     A = (R - np.mean(R)) / np.std(R)\n",
    "#     # perform the parameter update. The matrix multiply below\n",
    "#     # is just an efficient way to sum up all the rows of the noise matrix N,\n",
    "#     # where each row N[j] is weighted by A[j]\n",
    "#     w = w + alpha / (npop*sigma) * np.dot(N.T, A)\n",
    "# print('last w: %s, reward: %f' % (str(w), f(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "for step in range(100):\n",
    "    env.render()\n",
    "    new_observation, reward, done, info = env.step(w)\n",
    "    if (step % 10 == 0):\n",
    "        print (step)\n",
    "    if (done == True):\n",
    "        break \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
